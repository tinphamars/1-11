# Kiáº¿n TrÃºc & CÃ¡ch Hoáº¡t Äá»™ng cá»§a RAG Chatbot API

## ğŸ“‹ Tá»•ng Quan

RAG (Retrieval-Augmented Generation) Chatbot API lÃ  há»‡ thá»‘ng AI káº¿t há»£p viá»‡c tÃ¬m kiáº¿m thÃ´ng tin tá»« documents vá»›i kháº£ nÄƒng sinh text cá»§a GPT Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  cÃ³ ngá»¯ cáº£nh.

### NguyÃªn Táº¯c Hoáº¡t Äá»™ng

```
Documents â†’ Embeddings â†’ Vector DB â†’ Search â†’ Context â†’ GPT â†’ Answer
```

## ğŸ—ï¸ Kiáº¿n TrÃºc Há»‡ Thá»‘ng

### SÆ¡ Äá»“ Tá»•ng Quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     RAG CHATBOT API                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚   FastAPI    â”‚      â”‚   Swagger    â”‚                    â”‚
â”‚  â”‚   Endpoints  â”‚â—„â”€â”€â”€â”€â–ºâ”‚   UI/Docs    â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚         â”‚                                                    â”‚
â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚         â–¼          â–¼              â–¼              â–¼          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Chat   â”‚ â”‚ Document â”‚ â”‚  Upload  â”‚ â”‚  Status  â”‚     â”‚
â”‚  â”‚ Service  â”‚ â”‚ Service  â”‚ â”‚ Service  â”‚ â”‚ Service  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚       â”‚            â”‚             â”‚                          â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                    â–¼                                         â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚         â”‚   ChromaDB          â”‚                            â”‚
â”‚         â”‚   Vector Database   â”‚                            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                    â”‚                                         â”‚
â”‚                    â–¼                                         â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚         â”‚   OpenAI API        â”‚                            â”‚
â”‚         â”‚   - Embeddings      â”‚                            â”‚
â”‚         â”‚   - Chat GPT        â”‚                            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Quy TrÃ¬nh Hoáº¡t Äá»™ng Chi Tiáº¿t

### Phase 1: Khá»Ÿi Äá»™ng & Load Documents

```mermaid
graph TD
    A[Start Application] --> B[Load .env Config]
    B --> C[Initialize Services]
    C --> D{AUTO_LOAD_ON_STARTUP?}
    D -->|Yes| E[Scan ./documents folder]
    D -->|No| F[Ready to accept requests]
    E --> G[Find all supported files]
    G --> H[Process each file]
    H --> I[Split into chunks]
    I --> J[Generate embeddings]
    J --> K[Save to ChromaDB]
    K --> F
```

#### BÆ°á»›c 1: QuÃ©t ThÆ° Má»¥c Documents

```python
# Trong document_service.py

def auto_load_documents():
    """
    Tá»± Ä‘á»™ng load documents tá»« thÆ° má»¥c máº·c Ä‘á»‹nh
    """
    # 1. XÃ¡c Ä‘á»‹nh thÆ° má»¥c
    documents_folder = Path("./documents")
    
    # 2. TÃ¬m táº¥t cáº£ files theo pattern
    file_patterns = ["*.py", "*.md", "*.txt", "*.json", 
                     "*.yaml", "*.docx", "*.pdf"]
    
    # 3. Lá»c file há»£p lá»‡
    valid_files = []
    for pattern in file_patterns:
        for file_path in documents_folder.rglob(pattern):
            # Kiá»ƒm tra size
            if file_path.stat().st_size <= MAX_FILE_SIZE_MB * 1024 * 1024:
                valid_files.append(file_path)
    
    # 4. Xá»­ lÃ½ tá»«ng file
    for file_path in valid_files:
        process_single_file(file_path)
```

#### BÆ°á»›c 2: Xá»­ LÃ½ File

```python
def _process_single_file(file_path):
    """
    Xá»­ lÃ½ má»™t file duy nháº¥t
    """
    # 1. Chá»n loader phÃ¹ há»£p
    loader = _get_loader(file_path)
    
    # 2. Load ná»™i dung
    documents = loader.load()
    
    # 3. Split thÃ nh chunks
    chunks = text_splitter.split_documents(documents)
    
    # 4. ThÃªm metadata
    for chunk in chunks:
        chunk.metadata = {
            "source": str(file_path),
            "file_type": file_path.suffix,
            "file_name": file_path.name,
            "file_size": file_path.stat().st_size
        }
    
    return chunks
```

**VÃ­ dá»¥ thá»±c táº¿:**

```
File: employee_management_system/README.md (5,120 bytes)
    â†“
Load content: "# Há»‡ Thá»‘ng Quáº£n LÃ½ NhÃ¢n ViÃªn\n\n## Tá»•ng Quan..."
    â†“
Split into chunks (chunk_size=1000, overlap=200):
    Chunk 1: "# Há»‡ Thá»‘ng Quáº£n LÃ½ NhÃ¢n ViÃªn\n\n## Tá»•ng Quan..."
    Chunk 2: "...## Äáº·c TrÆ°ng ChÃ­nh\n### Quáº£n LÃ½ PhÃ²ng Ban..."
    Chunk 3: "...### Quáº£n LÃ½ NhÃ¢n ViÃªn\n- ThÃ´ng tin cÃ¡ nhÃ¢n..."
    Chunk 4: "...## CÃ´ng Nghá»‡ Sá»­ Dá»¥ng\n- FastAPI..."
    Chunk 5: "...## API Endpoints\nPOST /employees..."
    Chunk 6: "...## Báº£o Máº­t\n- JWT Token..."
    â†“
Total: 6 chunks
```

#### BÆ°á»›c 3: Táº¡o Embeddings

```python
def _add_documents_to_db(documents):
    """
    Chuyá»ƒn Ä‘á»•i text thÃ nh vector embeddings
    """
    # 1. TrÃ­ch xuáº¥t text tá»« chunks
    texts = [doc.page_content for doc in documents]
    
    # 2. Gá»i OpenAI Embedding API
    embeddings = openai_embeddings.embed_documents(texts)
    
    # 3. LÆ°u vÃ o ChromaDB
    collection.add(
        embeddings=embeddings,
        documents=texts,
        metadatas=[doc.metadata for doc in documents],
        ids=[f"doc_{i}_{hash(text[:100])}" for i, text in enumerate(texts)]
    )
```

**Embedding lÃ  gÃ¬?**

Embedding chuyá»ƒn Ä‘á»•i text thÃ nh vector sá»‘ Ä‘á»ƒ mÃ¡y tÃ­nh hiá»ƒu ngá»¯ nghÄ©a:

```
Text: "Há»‡ thá»‘ng quáº£n lÃ½ nhÃ¢n viÃªn giÃºp theo dÃµi thÃ´ng tin nhÃ¢n sá»±"
    â†“ OpenAI text-embedding-ada-002
Vector (1536 chiá»u): 
[0.023, -0.891, 0.234, 0.567, -0.123, 0.789, ..., 0.456]
           â†‘
    Má»—i sá»‘ Ä‘áº¡i diá»‡n cho má»™t "khÃ­a cáº¡nh" ngá»¯ nghÄ©a
```

**Táº¡i sao cáº§n Embeddings?**

- Text cÃ³ ngá»¯ nghÄ©a giá»‘ng nhau â†’ Vector gáº§n nhau
- Cho phÃ©p tÃ¬m kiáº¿m theo Ã½ nghÄ©a, khÃ´ng chá»‰ tá»« khÃ³a
- "nhÃ¢n viÃªn" vÃ  "ngÆ°á»i lao Ä‘á»™ng" â†’ vectors tÆ°Æ¡ng tá»±

### Phase 2: Chat & Tráº£ Lá»i CÃ¢u Há»i

```mermaid
graph TD
    A[User Question] --> B[Create Query Embedding]
    B --> C[Search ChromaDB]
    C --> D[Get Top K Similar Documents]
    D --> E[Build Context]
    E --> F[Call GPT with Context]
    F --> G[Generate Answer]
    G --> H[Return Response + Sources]
```

#### BÆ°á»›c 1: Nháº­n CÃ¢u Há»i

```http
POST /chat
Content-Type: application/json

{
  "message": "LÃ m sao Ä‘á»ƒ táº¡o nhÃ¢n viÃªn má»›i trong há»‡ thá»‘ng?",
  "conversation_id": null,
  "max_tokens": 1000,
  "temperature": 0.7
}
```

#### BÆ°á»›c 2: Táº¡o Query Embedding

```python
# Trong document_service.py

def search_similar_documents(query, k=5):
    """
    TÃ¬m documents tÆ°Æ¡ng tá»± vá»›i cÃ¢u há»i
    """
    # 1. Táº¡o embedding cho cÃ¢u há»i
    query_embedding = openai_embeddings.embed_query(query)
    
    # query_embedding = [0.123, -0.456, 0.789, ...]
```

#### BÆ°á»›c 3: TÃ¬m Kiáº¿m Vector Similarity

```python
    # 2. TÃ¬m trong ChromaDB
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=k,  # Láº¥y top 5
        include=["documents", "metadatas", "distances"]
    )
```

**Vector Similarity Search hoáº¡t Ä‘á»™ng tháº¿ nÃ o?**

```
Query Vector:     [0.1, 0.9, 0.2, ...]

Document Vectors in DB:
Doc 1: [0.12, 0.88, 0.19, ...]  â†’ Cosine similarity: 0.96 âœ“ (Very similar)
Doc 2: [0.5, 0.3, 0.8, ...]     â†’ Cosine similarity: 0.75 âœ“ (Similar)
Doc 3: [-0.8, 0.1, -0.9, ...]   â†’ Cosine similarity: 0.32 âœ— (Not similar)
Doc 4: [0.11, 0.91, 0.21, ...]  â†’ Cosine similarity: 0.98 âœ“ (Most similar!)
Doc 5: [0.2, 0.7, 0.3, ...]     â†’ Cosine similarity: 0.85 âœ“ (Similar)

â†’ Return top 5: Doc 4, Doc 1, Doc 5, Doc 2, (Doc 6...)
```

**Káº¿t quáº£ tÃ¬m kiáº¿m:**

```json
[
  {
    "content": "## API Endpoints\n\n### Employees\n```\nPOST /api/v1/employees\n```\nTáº¡o nhÃ¢n viÃªn má»›i vá»›i thÃ´ng tin: fullName, email, phone, departmentId...",
    "metadata": {
      "source": "./documents/employee_management_system/docs/API_DOCUMENTATION.md",
      "file_name": "API_DOCUMENTATION.md"
    },
    "score": 0.92
  },
  {
    "content": "class Employee:\n    fullName: str\n    email: str\n    phone: str\n    departmentId: int\n    position: str\n    hireDate: date\n    salary: float",
    "metadata": {
      "source": "./documents/employee_management_system/models/employee.py"
    },
    "score": 0.88
  },
  {
    "content": "### ThÃªm NhÃ¢n ViÃªn Má»›i\n\n1. Truy cáº­p menu Employees\n2. Click nÃºt 'ThÃªm má»›i'\n3. Äiá»n form vá»›i thÃ´ng tin báº¯t buá»™c\n4. Upload CV náº¿u cÃ³\n5. Click 'LÆ°u'",
    "metadata": {
      "source": "./documents/employee_management_system/docs/USER_GUIDE.md"
    },
    "score": 0.85
  }
]
```

#### BÆ°á»›c 4: XÃ¢y Dá»±ng Context

```python
# Trong chat_service.py

def chat(message, conversation_id=None):
    """
    Xá»­ lÃ½ chat vá»›i RAG
    """
    # 1. TÃ¬m documents liÃªn quan
    similar_docs = document_service.search_similar_documents(
        message, 
        k=5
    )
    
    # 2. XÃ¢y dá»±ng context tá»« documents tÃ¬m Ä‘Æ°á»£c
    context = "\n\n---\n\n".join([
        f"Document {i+1} (Source: {doc['metadata']['file_name']}):\n{doc['content']}"
        for i, doc in enumerate(similar_docs)
    ])
```

**Context Ä‘Æ°á»£c táº¡o:**

```
Document 1 (Source: API_DOCUMENTATION.md):
## API Endpoints

### Employees
```
POST /api/v1/employees
```
Táº¡o nhÃ¢n viÃªn má»›i vá»›i thÃ´ng tin: fullName, email, phone, departmentId...

---

Document 2 (Source: employee.py):
class Employee:
    fullName: str
    email: str
    phone: str
    departmentId: int
    position: str
    hireDate: date
    salary: float

---

Document 3 (Source: USER_GUIDE.md):
### ThÃªm NhÃ¢n ViÃªn Má»›i

1. Truy cáº­p menu Employees
2. Click nÃºt 'ThÃªm má»›i'
3. Äiá»n form vá»›i thÃ´ng tin báº¯t buá»™c
4. Upload CV náº¿u cÃ³
5. Click 'LÆ°u'
```

#### BÆ°á»›c 5: Gá»i GPT

```python
    # 3. Táº¡o messages cho GPT
    messages = [
        {
            "role": "system",
            "content": f"""Báº¡n lÃ  trá»£ lÃ½ AI thÃ´ng minh, giÃºp ngÆ°á»i dÃ¹ng tráº£ lá»i cÃ¢u há»i vá» dá»± Ã¡n dá»±a trÃªn tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p.

Dá»±a vÃ o context sau Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng:

{context}

HÆ°á»›ng dáº«n:
- Tráº£ lá»i chÃ­nh xÃ¡c dá»±a trÃªn context
- Náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin, nÃ³i rÃµ
- TrÃ­ch dáº«n nguá»“n khi cÃ³ thá»ƒ
- Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t rÃµ rÃ ng, dá»… hiá»ƒu"""
        },
        {
            "role": "user",
            "content": message
        }
    ]
    
    # 4. Gá»i OpenAI GPT
    response = openai_client.chat.completions.create(
        model="GPT-4o-mini",
        messages=messages,
        temperature=0.7,
        max_tokens=1000
    )
    
    answer = response.choices[0].message.content
```

#### BÆ°á»›c 6: Tráº£ Vá» Káº¿t Quáº£

```json
{
  "response": "Äá»ƒ táº¡o nhÃ¢n viÃªn má»›i trong há»‡ thá»‘ng, báº¡n cÃ³ thá»ƒ thá»±c hiá»‡n theo cÃ¡c cÃ¡ch sau:\n\n**1. Qua Giao Diá»‡n Web:**\n- Truy cáº­p menu 'Employees'\n- Click nÃºt 'ThÃªm má»›i'\n- Äiá»n form vá»›i cÃ¡c thÃ´ng tin báº¯t buá»™c: Há» tÃªn, Email, Sá»‘ Ä‘iá»‡n thoáº¡i, PhÃ²ng ban, Chá»©c vá»¥\n- Upload CV náº¿u cÃ³\n- Click 'LÆ°u'\n\n**2. Qua API:**\n```\nPOST /api/v1/employees\n{\n  \"fullName\": \"Nguyá»…n VÄƒn A\",\n  \"email\": \"a.nguyen@company.com\",\n  \"phone\": \"0912345678\",\n  \"departmentId\": 1,\n  \"position\": \"Developer\",\n  \"hireDate\": \"2024-01-15\",\n  \"salary\": 15000000\n}\n```\n\n**CÃ¡c trÆ°á»ng báº¯t buá»™c:**\n- fullName (Há» tÃªn)\n- email (Email há»£p lá»‡)\n- phone (Sá»‘ Ä‘iá»‡n thoáº¡i)\n- departmentId (ID phÃ²ng ban)\n\n*Nguá»“n: API_DOCUMENTATION.md, USER_GUIDE.md*",
  
  "conversation_id": "550e8400-e29b-41d4-a716-446655440000",
  
  "sources": [
    {
      "content": "## API Endpoints...",
      "metadata": {
        "source": "./documents/employee_management_system/docs/API_DOCUMENTATION.md",
        "file_name": "API_DOCUMENTATION.md"
      },
      "score": 0.92,
      "rank": 1
    },
    {
      "content": "class Employee:...",
      "metadata": {
        "source": "./documents/employee_management_system/models/employee.py"
      },
      "score": 0.88,
      "rank": 2
    },
    {
      "content": "### ThÃªm NhÃ¢n ViÃªn Má»›i...",
      "metadata": {
        "source": "./documents/employee_management_system/docs/USER_GUIDE.md"
      },
      "score": 0.85,
      "rank": 3
    }
  ],
  
  "metadata": {
    "model": "GPT-4o-mini",
    "tokens_used": 856,
    "retrieval_count": 3,
    "processing_time_ms": 1250
  }
}
```

## ğŸ—„ï¸ Cáº¥u TrÃºc ChromaDB

### Collection Schema

```python
Collection: "documents"
â”œâ”€â”€ Metadata
â”‚   â”œâ”€â”€ name: "documents"
â”‚   â”œâ”€â”€ description: "RAG documents collection"
â”‚   â””â”€â”€ created_at: "2024-10-30T10:30:00Z"
â”‚
â””â”€â”€ Documents (Chunks)
    â”œâ”€â”€ Document ID: "doc_0_abc123def456"
    â”‚   â”œâ”€â”€ Embedding: [1536 dimensions float array]
    â”‚   â”œâ”€â”€ Text: "Há»‡ thá»‘ng quáº£n lÃ½ nhÃ¢n viÃªn lÃ ..."
    â”‚   â””â”€â”€ Metadata:
    â”‚       â”œâ”€â”€ source: "./documents/README.md"
    â”‚       â”œâ”€â”€ file_type: ".md"
    â”‚       â”œâ”€â”€ file_name: "README.md"
    â”‚       â”œâ”€â”€ file_size: 5120
    â”‚       â””â”€â”€ chunk_index: 0
    â”‚
    â”œâ”€â”€ Document ID: "doc_1_ghi789jkl012"
    â”‚   â”œâ”€â”€ Embedding: [1536 dimensions]
    â”‚   â”œâ”€â”€ Text: "## Äáº·c TrÆ°ng ChÃ­nh..."
    â”‚   â””â”€â”€ Metadata: {...}
    â”‚
    â””â”€â”€ ... (nhiá»u documents khÃ¡c)
```

### VÃ­ Dá»¥ Thá»±c Táº¿

```json
{
  "id": "doc_42_a1b2c3d4e5f6",
  "embedding": [
    0.023145, -0.891234, 0.234567, 0.567890, -0.123456,
    0.789012, 0.345678, -0.901234, 0.456789, 0.012345,
    // ... 1526 sá»‘ ná»¯a (tá»•ng 1536)
  ],
  "document": "POST /api/v1/employees\n\nTáº¡o nhÃ¢n viÃªn má»›i trong há»‡ thá»‘ng.\n\n**Request Body:**\n```json\n{\n  \"fullName\": \"string\",\n  \"email\": \"string\",\n  \"phone\": \"string\",\n  \"departmentId\": \"integer\",\n  \"position\": \"string\",\n  \"hireDate\": \"date\",\n  \"salary\": \"float\"\n}\n```\n\n**Response:** 201 Created",
  "metadata": {
    "source": "./documents/employee_management_system/docs/API_DOCUMENTATION.md",
    "file_type": ".md",
    "file_name": "API_DOCUMENTATION.md",
    "file_size": 15840,
    "chunk_index": 7
  }
}
```

## ğŸ”§ CÃ¡c ThÃ nh Pháº§n Ká»¹ Thuáº­t

### 1. Text Splitter

**RecursiveCharacterTextSplitter** chia text thÃ´ng minh:

```python
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,        # KÃ­ch thÆ°á»›c má»—i chunk
    chunk_overlap=200,      # Overlap Ä‘á»ƒ giá»¯ ngá»¯ cáº£nh
    length_function=len,
    separators=["\n\n", "\n", " ", ""]  # Æ¯u tiÃªn chia theo paragraph
)
```

**VÃ­ dá»¥:**

```
Original text (2500 chars):
"# Há»‡ Thá»‘ng Quáº£n LÃ½\n\n## Tá»•ng Quan\nHá»‡ thá»‘ng giÃºp...[800 chars]...\n\n## TÃ­nh NÄƒng\n### Quáº£n LÃ½ NhÃ¢n ViÃªn\n...[1200 chars]...\n\n## API\nEndpoints chÃ­nh..."

After splitting:
Chunk 1 (1000 chars): "# Há»‡ Thá»‘ng Quáº£n LÃ½\n\n## Tá»•ng Quan..."
                        â””â”€ overlap 200 chars â”€â”
Chunk 2 (1000 chars):                    "...Há»‡ thá»‘ng giÃºp...\n\n## TÃ­nh NÄƒng..."
                                          â””â”€ overlap 200 chars â”€â”
Chunk 3 (700 chars):                                      "...### Quáº£n LÃ½...\n\n## API..."
```

**Táº¡i sao cáº§n overlap?**

- Giá»¯ ngá»¯ cáº£nh giá»¯a cÃ¡c chunks
- TrÃ¡nh máº¥t thÃ´ng tin á»Ÿ ranh giá»›i
- TÄƒng kháº£ nÄƒng tÃ¬m kiáº¿m chÃ­nh xÃ¡c

### 2. Document Loaders

```python
def _get_loader(file_path):
    """Chá»n loader phÃ¹ há»£p theo extension"""
    extension = file_path.suffix.lower()
    
    loaders = {
        ".py": PythonLoader,
        ".md": UnstructuredMarkdownLoader,
        ".json": JSONLoader,
        ".docx": UnstructuredWordDocumentLoader,
        ".pdf": PyPDFLoader,
        ".txt": TextLoader,
        ".yaml": TextLoader,
        ".yml": TextLoader,
        ".rst": TextLoader
    }
    
    return loaders.get(extension, TextLoader)(str(file_path))
```

### 3. OpenAI Integration

#### Embeddings

```python
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(
    openai_api_key=settings.openai_api_key,
    model="text-embedding-ada-002"
)

# Single text
vector = embeddings.embed_query("Há»‡ thá»‘ng quáº£n lÃ½ nhÃ¢n viÃªn")
# â†’ [0.023, -0.891, ...] (1536 dimensions)

# Multiple texts
vectors = embeddings.embed_documents([
    "Text 1",
    "Text 2",
    "Text 3"
])
# â†’ [[...], [...], [...]]
```

#### Chat Completion

```python
import openai

client = openai.OpenAI(
    base_url="https://aiportalapi.stu-platform.live/jpe",
    api_key=settings.openai_api_key
)

response = client.chat.completions.create(
    model="GPT-4o-mini",
    messages=[
        {"role": "system", "content": "System prompt with context..."},
        {"role": "user", "content": "User question..."}
    ],
    temperature=0.7,
    max_tokens=1000
)

answer = response.choices[0].message.content
```

### 4. ChromaDB Operations

#### Khá»Ÿi táº¡o

```python
import chromadb
from chromadb.config import Settings

client = chromadb.PersistentClient(
    path="./chroma_db",
    settings=Settings(anonymized_telemetry=False)
)

collection = client.get_or_create_collection(
    name="documents",
    metadata={"description": "RAG documents collection"}
)
```

#### ThÃªm documents

```python
collection.add(
    embeddings=[[0.1, 0.2, ...], [0.3, 0.4, ...]],
    documents=["Text 1", "Text 2"],
    metadatas=[{"source": "file1.md"}, {"source": "file2.md"}],
    ids=["doc_0", "doc_1"]
)
```

#### TÃ¬m kiáº¿m

```python
results = collection.query(
    query_embeddings=[[0.15, 0.25, ...]],
    n_results=5,
    include=["documents", "metadatas", "distances"]
)
```

## âš¡ Tá»‘i Æ¯u HÃ³a

### 1. Concurrent Processing

```python
# Xá»­ lÃ½ nhiá»u files song song
tasks = [_process_single_file(file) for file in valid_files]
results = await asyncio.gather(*tasks, return_exceptions=True)
```

### 2. Thread Pool for I/O

```python
executor = ThreadPoolExecutor(max_workers=4)

# Cháº¡y blocking operations trong thread pool
embeddings = await asyncio.get_event_loop().run_in_executor(
    executor, 
    openai_embeddings.embed_documents, 
    texts
)
```

### 3. Batch Processing

```python
# Táº¡o embeddings theo batch thay vÃ¬ tá»«ng cÃ¡i má»™t
BATCH_SIZE = 100

for i in range(0, len(documents), BATCH_SIZE):
    batch = documents[i:i + BATCH_SIZE]
    embeddings = create_embeddings(batch)
    save_to_db(embeddings)
```

### 4. Caching

ChromaDB tá»± Ä‘á»™ng cache:
- LÆ°u persistent trÃªn disk
- KhÃ´ng cáº§n reload khi restart
- TÃ¬m kiáº¿m nhanh vá»›i index

## ğŸ“Š Metrics & Monitoring

### Metrics Quan Trá»ng

```python
# Document processing
- documents_processed_total
- documents_failed_total
- chunks_created_total
- processing_time_seconds

# Search
- search_queries_total
- search_latency_seconds
- search_results_count

# Chat
- chat_requests_total
- chat_response_time_seconds
- tokens_used_total
- context_relevance_score
```

### Logging

```python
import logging

logger = logging.getLogger(__name__)

# Info level
logger.info(f"Auto-loaded {count} files, {chunks} chunks")

# Warning level
logger.warning(f"File too large: {file_path}")

# Error level
logger.error(f"Failed to process {file_path}: {error}")
```

## ğŸ¯ Best Practices

### 1. Chunk Size Optimization

```
QuÃ¡ nhá» (< 500):  Máº¥t ngá»¯ cáº£nh, nhiá»u chunks khÃ´ng cáº§n thiáº¿t
Tá»‘i Æ°u (800-1200): CÃ¢n báº±ng ngá»¯ cáº£nh vÃ  Ä‘á»™ chÃ­nh xÃ¡c
QuÃ¡ lá»›n (> 2000):  GPT cÃ³ thá»ƒ bá»‹ overwhelm, cháº­m
```

### 2. Retrieval K Value

```python
k = 3:  Nhanh, Ã­t context, cÃ³ thá»ƒ thiáº¿u thÃ´ng tin
k = 5:  CÃ¢n báº±ng tá»‘t (khuyáº¿n nghá»‹)
k = 10: Nhiá»u context, nhÆ°ng cÃ³ thá»ƒ cÃ³ noise
```

### 3. Temperature Settings

```
0.0 - 0.3:  Deterministic, chÃ­nh xÃ¡c, láº·p láº¡i
0.5 - 0.7:  CÃ¢n báº±ng (khuyáº¿n nghá»‹ cho RAG)
0.8 - 1.0:  SÃ¡ng táº¡o, nhÆ°ng cÃ³ thá»ƒ sai lá»‡ch
```

### 4. Context Window Management

```
GPT-4o-mini: 128k tokens context window
Má»—i token â‰ˆ 4 chars

VÃ­ dá»¥:
5 documents Ã— 1000 chars = 5000 chars â‰ˆ 1250 tokens
System prompt: ~500 tokens
User message: ~50 tokens
Response budget: ~1000 tokens
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: ~2800 tokens (cÃ²n ráº¥t nhiá»u cho context)
```

## ğŸ” Troubleshooting

### Váº¥n Äá» ThÆ°á»ng Gáº·p

#### 1. Documents khÃ´ng Ä‘Æ°á»£c load

**Triá»‡u chá»©ng:**
```
âš ï¸ No documents found to auto-load
```

**NguyÃªn nhÃ¢n & Giáº£i phÃ¡p:**
- ThÆ° má»¥c `./documents` trá»‘ng â†’ ThÃªm files
- File extension khÃ´ng Ä‘Æ°á»£c há»— trá»£ â†’ Kiá»ƒm tra `SUPPORTED_EXTENSIONS`
- File quÃ¡ lá»›n â†’ TÄƒng `MAX_FILE_SIZE_MB`

#### 2. TÃ¬m kiáº¿m khÃ´ng chÃ­nh xÃ¡c

**Triá»‡u chá»©ng:**
- CÃ¢u tráº£ lá»i khÃ´ng liÃªn quan
- Documents tráº£ vá» score tháº¥p

**Giáº£i phÃ¡p:**
- Giáº£m `chunk_size` Ä‘á»ƒ tÄƒng Ä‘á»™ chi tiáº¿t
- TÄƒng `RETRIEVAL_K` Ä‘á»ƒ cÃ³ nhiá»u context hÆ¡n
- Kiá»ƒm tra quality cá»§a documents (cÃ³ Ä‘á»§ thÃ´ng tin?)

#### 3. Response cháº­m

**Triá»‡u chá»©ng:**
- API timeout
- Latency cao

**Giáº£i phÃ¡p:**
- Giáº£m `RETRIEVAL_K`
- Giáº£m `max_tokens` trong response
- Sá»­ dá»¥ng cache cho queries phá»• biáº¿n
- Scale horizontal vá»›i load balancer

#### 4. OpenAI API errors

**Triá»‡u chá»©ng:**
```
401 Unauthorized
429 Rate Limit Exceeded
500 Internal Server Error
```

**Giáº£i phÃ¡p:**
- Kiá»ƒm tra `OPENAI_API_KEY`
- ThÃªm retry logic vá»›i exponential backoff
- Monitor usage quota
- Sá»­ dá»¥ng fallback model

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

### Technologies

- **FastAPI**: https://fastapi.tiangolo.com/
- **LangChain**: https://python.langchain.com/
- **ChromaDB**: https://docs.trychroma.com/
- **OpenAI API**: https://platform.openai.com/docs

### Papers & Concepts

- **RAG (Retrieval-Augmented Generation)**: 
  - Paper: "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
  
- **Vector Embeddings**:
  - Understanding semantic search and vector databases
  
- **Chunking Strategies**:
  - Optimal document segmentation for RAG systems

### Community

- **LangChain Discord**: Discussions about RAG patterns
- **ChromaDB Community**: Vector database optimization
- **OpenAI Forum**: API best practices

---

## ğŸš€ Káº¿t Luáº­n

RAG Chatbot API káº¿t há»£p sá»©c máº¡nh cá»§a:

1. **Vector Search** (ChromaDB): TÃ¬m kiáº¿m ngá»¯ nghÄ©a nhanh vÃ  chÃ­nh xÃ¡c
2. **Embeddings** (OpenAI): Chuyá»ƒn Ä‘á»•i text thÃ nh vectors cÃ³ Ã½ nghÄ©a
3. **LLM** (GPT): Sinh cÃ¢u tráº£ lá»i tá»± nhiÃªn dá»±a trÃªn context
4. **Document Processing** (LangChain): Xá»­ lÃ½ Ä‘a dáº¡ng Ä‘á»‹nh dáº¡ng files

Há»‡ thá»‘ng nÃ y cho phÃ©p:
- âœ… Tráº£ lá»i cÃ¢u há»i chÃ­nh xÃ¡c dá»±a trÃªn documents
- âœ… Tá»± Ä‘á»™ng cáº­p nháº­t khi thÃªm tÃ i liá»‡u má»›i
- âœ… Scale tá»‘t vá»›i lÆ°á»£ng documents lá»›n
- âœ… TrÃ­ch dáº«n nguá»“n minh báº¡ch
- âœ… Dá»… dÃ ng tÃ­ch há»£p vÃ o á»©ng dá»¥ng

**Happy Coding! ğŸ‰**